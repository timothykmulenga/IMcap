{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OfuGIZzPhgp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mX2VKgGs5og"
   },
   "outputs": [],
   "source": [
    "image_path = '/ImageCap/imagesB/flickr30k-images/'\n",
    "feat_path = '/ImageCap/image_feat/'\n",
    "text_path = '/ImageCap/captions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKewahlZv-yf"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(text_path,delimiter='|', skipinitialspace=True) #in this csv, | is being used as delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Clh1ZP87BzfO"
   },
   "outputs": [],
   "source": [
    "image_name_list = list(set(df['image_name'])) #obtaining unique instance name of each image\n",
    "image_path_list = list(map(lambda arg: image_path + arg, image_name_list))\n",
    "feat_path_list = list(map(lambda arg: feat_path + arg, image_name_list))\n",
    "#Its imp to keep images and features in different directories so as to avoid Colab's infamous I/O error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lFakMVw2LctS",
    "outputId": "34aee0e6-48c2-4db3-f387-35d5beaecf9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31783"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cvkgeej0CAcH"
   },
   "outputs": [],
   "source": [
    "def feat_extract():#Here we are performing surgery on a pretrained Inception V3 model so as to just obtain a model upto last conv layer\n",
    "\n",
    "  IV3 = tf.keras.applications.InceptionV3(include_top=False,weights='imagenet') #creating an inceptionV3 instance without last classification layer\n",
    "\n",
    "  x_in = IV3.input #we will feed input to the input layer of inception V3\n",
    "  x_out= IV3.layers[-1].output #output of the last conv layer in inception V3 will will be taken as output\n",
    "\n",
    "  return tf.keras.Model(inputs=x_in, outputs=x_out) #Output will be of dimention 8*8*2048\n",
    "\n",
    "mod_fe = feat_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtXt-gep8pcm"
   },
   "outputs": [],
   "source": [
    "mod_fe.save('/ImageCap/IV3_feat.h5') #saving because, we will also need it during evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nXyORij2V2wo"
   },
   "outputs": [],
   "source": [
    "def load_image(arg):\n",
    "    img = tf.io.read_file(arg)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img, arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nj15W-ufVlHD"
   },
   "outputs": [],
   "source": [
    "#Features are being extracted seperately so as to avoid this part from becoming a bottleneck in further training\n",
    "#Apart from this, features are cached in hard disk instead of RAM because of RAM's limitation in Collab\n",
    "image_dataset = tf.data.Dataset.from_tensor_slices(image_path_list)\n",
    "image_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) #this is a map() extention for \"Dataset\" type stucture \n",
    "image_dataset = image_dataset.batch(32) #Since Inception V3 expects batch input anyways, so to leverage possible vectorization its better to send input in batches\n",
    "\n",
    "for img, path in image_dataset:\n",
    "  batch_features = mod_fe(img)\n",
    "  batch_features = tf.reshape(batch_features,(batch_features.shape[0], 8*8, batch_features.shape[3]))\n",
    "  \n",
    "  for bf, p in zip(batch_features, path):\n",
    "    path_ = p.numpy().decode(\"utf-8\") #p is needed to be decoded as string becuase it is originally obtained as numpy object\n",
    "    path_ = feat_path + path_[len(image_path):] # path_[len(image_path):] extracts name of image which is then concatenated to feature path \n",
    "    np.save(path_, bf.numpy()) #saves feature matrix with same name as that of image\n",
    "    #Feature matrix is of dim 64x2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UurHUJfIaIGO",
    "outputId": "ae924019-779d-45ba-ed4e-758495a929ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31783"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying quantity\n",
    "import os, os.path\n",
    "path = '/ImageCap/image_feat'\n",
    "num_files = len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n",
    "\n",
    "num_files"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Image Features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
